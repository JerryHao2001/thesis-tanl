{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 100.0,
  "eval_steps": 500,
  "global_step": 56300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 0.5656650066375732,
      "learning_rate": 0.0004950088809946714,
      "loss": 0.0943,
      "step": 563
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.11575667560100555,
      "learning_rate": 0.0004900088809946714,
      "loss": 0.0283,
      "step": 1126
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.03882916644215584,
      "learning_rate": 0.0004850088809946714,
      "loss": 0.0208,
      "step": 1689
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.21248023211956024,
      "learning_rate": 0.00048000888099467145,
      "loss": 0.0166,
      "step": 2252
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.05476236715912819,
      "learning_rate": 0.00047500888099467144,
      "loss": 0.0134,
      "step": 2815
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2971833348274231,
      "learning_rate": 0.0004700088809946714,
      "loss": 0.0113,
      "step": 3378
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.10389654338359833,
      "learning_rate": 0.0004650088809946714,
      "loss": 0.0094,
      "step": 3941
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.1301674097776413,
      "learning_rate": 0.0004600088809946714,
      "loss": 0.0085,
      "step": 4504
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.30880871415138245,
      "learning_rate": 0.00045500888099467144,
      "loss": 0.0069,
      "step": 5067
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0866784080862999,
      "learning_rate": 0.0004500088809946714,
      "loss": 0.0072,
      "step": 5630
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.053526587784290314,
      "learning_rate": 0.0004450088809946714,
      "loss": 0.0059,
      "step": 6193
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.10624924302101135,
      "learning_rate": 0.0004400088809946714,
      "loss": 0.0054,
      "step": 6756
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.19492635130882263,
      "learning_rate": 0.0004350088809946714,
      "loss": 0.0051,
      "step": 7319
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.014903824776411057,
      "learning_rate": 0.0004300088809946714,
      "loss": 0.0046,
      "step": 7882
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.05265448987483978,
      "learning_rate": 0.00042500888099467136,
      "loss": 0.004,
      "step": 8445
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.09708180278539658,
      "learning_rate": 0.00042000888099467146,
      "loss": 0.0041,
      "step": 9008
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.22583504021167755,
      "learning_rate": 0.00041500888099467144,
      "loss": 0.0038,
      "step": 9571
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.1083952859044075,
      "learning_rate": 0.00041000888099467143,
      "loss": 0.0036,
      "step": 10134
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.4320572316646576,
      "learning_rate": 0.0004050088809946714,
      "loss": 0.0031,
      "step": 10697
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.09229586273431778,
      "learning_rate": 0.0004000088809946714,
      "loss": 0.0032,
      "step": 11260
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.005227798596024513,
      "learning_rate": 0.0003950088809946714,
      "loss": 0.003,
      "step": 11823
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.21947559714317322,
      "learning_rate": 0.00039000888099467143,
      "loss": 0.0026,
      "step": 12386
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.03612225502729416,
      "learning_rate": 0.0003850088809946714,
      "loss": 0.0026,
      "step": 12949
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.08361423760652542,
      "learning_rate": 0.0003800088809946714,
      "loss": 0.0025,
      "step": 13512
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.14622507989406586,
      "learning_rate": 0.0003750088809946714,
      "loss": 0.0025,
      "step": 14075
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.0038021609652787447,
      "learning_rate": 0.0003700088809946714,
      "loss": 0.0023,
      "step": 14638
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.019213713705539703,
      "learning_rate": 0.00036500888099467137,
      "loss": 0.0018,
      "step": 15201
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.053300537168979645,
      "learning_rate": 0.0003600088809946714,
      "loss": 0.002,
      "step": 15764
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.04484619200229645,
      "learning_rate": 0.00035500888099467145,
      "loss": 0.0019,
      "step": 16327
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.2034456431865692,
      "learning_rate": 0.00035000888099467143,
      "loss": 0.0019,
      "step": 16890
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.15310385823249817,
      "learning_rate": 0.0003450088809946714,
      "loss": 0.0019,
      "step": 17453
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.030538875609636307,
      "learning_rate": 0.0003400088809946714,
      "loss": 0.0019,
      "step": 18016
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.000823266280349344,
      "learning_rate": 0.0003350088809946714,
      "loss": 0.0015,
      "step": 18579
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.011281204409897327,
      "learning_rate": 0.00033000888099467144,
      "loss": 0.0015,
      "step": 19142
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.001003198092803359,
      "learning_rate": 0.0003250088809946714,
      "loss": 0.0013,
      "step": 19705
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.0005491271731443703,
      "learning_rate": 0.0003200088809946714,
      "loss": 0.0015,
      "step": 20268
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.1642204225063324,
      "learning_rate": 0.0003150088809946714,
      "loss": 0.0014,
      "step": 20831
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.0005018861265853047,
      "learning_rate": 0.0003100088809946714,
      "loss": 0.0013,
      "step": 21394
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.010472417809069157,
      "learning_rate": 0.00030500888099467137,
      "loss": 0.0013,
      "step": 21957
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.0034105766098946333,
      "learning_rate": 0.00030000888099467136,
      "loss": 0.0011,
      "step": 22520
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.05671847239136696,
      "learning_rate": 0.00029500888099467145,
      "loss": 0.001,
      "step": 23083
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.0007304272148758173,
      "learning_rate": 0.00029000888099467144,
      "loss": 0.0011,
      "step": 23646
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.04295174032449722,
      "learning_rate": 0.0002850088809946714,
      "loss": 0.0011,
      "step": 24209
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.018856709823012352,
      "learning_rate": 0.0002800088809946714,
      "loss": 0.001,
      "step": 24772
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.0026167421601712704,
      "learning_rate": 0.0002750088809946714,
      "loss": 0.001,
      "step": 25335
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.05407945439219475,
      "learning_rate": 0.0002700088809946714,
      "loss": 0.0012,
      "step": 25898
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.00019898747268598527,
      "learning_rate": 0.00026500888099467143,
      "loss": 0.0008,
      "step": 26461
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.0029776738956570625,
      "learning_rate": 0.0002600088809946714,
      "loss": 0.0007,
      "step": 27024
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.00012578426685649902,
      "learning_rate": 0.0002550088809946714,
      "loss": 0.0008,
      "step": 27587
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.14092102646827698,
      "learning_rate": 0.0002500088809946714,
      "loss": 0.001,
      "step": 28150
    },
    {
      "epoch": 51.0,
      "grad_norm": 0.004223900381475687,
      "learning_rate": 0.00024500888099467143,
      "loss": 0.0008,
      "step": 28713
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.000703080149833113,
      "learning_rate": 0.00024000888099467142,
      "loss": 0.0007,
      "step": 29276
    },
    {
      "epoch": 53.0,
      "grad_norm": 0.00041890889406204224,
      "learning_rate": 0.0002350088809946714,
      "loss": 0.0007,
      "step": 29839
    },
    {
      "epoch": 54.0,
      "grad_norm": 0.001861031400039792,
      "learning_rate": 0.0002300088809946714,
      "loss": 0.0007,
      "step": 30402
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.15038233995437622,
      "learning_rate": 0.0002250088809946714,
      "loss": 0.0006,
      "step": 30965
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.0853496789932251,
      "learning_rate": 0.0002200088809946714,
      "loss": 0.0005,
      "step": 31528
    },
    {
      "epoch": 57.0,
      "grad_norm": 0.12736526131629944,
      "learning_rate": 0.0002150088809946714,
      "loss": 0.0005,
      "step": 32091
    },
    {
      "epoch": 58.0,
      "grad_norm": 0.04119330644607544,
      "learning_rate": 0.00021000888099467142,
      "loss": 0.0005,
      "step": 32654
    },
    {
      "epoch": 59.0,
      "grad_norm": 0.09751923382282257,
      "learning_rate": 0.0002050088809946714,
      "loss": 0.0005,
      "step": 33217
    },
    {
      "epoch": 60.0,
      "grad_norm": 3.1906383810564876e-05,
      "learning_rate": 0.0002000088809946714,
      "loss": 0.0004,
      "step": 33780
    },
    {
      "epoch": 61.0,
      "grad_norm": 0.0011526137823238969,
      "learning_rate": 0.0001950088809946714,
      "loss": 0.0006,
      "step": 34343
    },
    {
      "epoch": 62.0,
      "grad_norm": 2.9877619454055093e-05,
      "learning_rate": 0.0001900088809946714,
      "loss": 0.0006,
      "step": 34906
    },
    {
      "epoch": 63.0,
      "grad_norm": 0.0001809804525692016,
      "learning_rate": 0.0001850088809946714,
      "loss": 0.0004,
      "step": 35469
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.000507521559484303,
      "learning_rate": 0.00018000888099467142,
      "loss": 0.0004,
      "step": 36032
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.00375617784447968,
      "learning_rate": 0.0001750088809946714,
      "loss": 0.0005,
      "step": 36595
    },
    {
      "epoch": 66.0,
      "grad_norm": 0.003989019431173801,
      "learning_rate": 0.0001700088809946714,
      "loss": 0.0003,
      "step": 37158
    },
    {
      "epoch": 67.0,
      "grad_norm": 0.0012929919175803661,
      "learning_rate": 0.0001650088809946714,
      "loss": 0.0003,
      "step": 37721
    },
    {
      "epoch": 68.0,
      "grad_norm": 0.10963276028633118,
      "learning_rate": 0.0001600088809946714,
      "loss": 0.0003,
      "step": 38284
    },
    {
      "epoch": 69.0,
      "grad_norm": 0.0005589593783952296,
      "learning_rate": 0.0001550088809946714,
      "loss": 0.0002,
      "step": 38847
    },
    {
      "epoch": 70.0,
      "grad_norm": 9.684199176263064e-05,
      "learning_rate": 0.00015000888099467143,
      "loss": 0.0003,
      "step": 39410
    },
    {
      "epoch": 71.0,
      "grad_norm": 0.004590925760567188,
      "learning_rate": 0.0001450088809946714,
      "loss": 0.0004,
      "step": 39973
    },
    {
      "epoch": 72.0,
      "grad_norm": 0.0028133748564869165,
      "learning_rate": 0.0001400088809946714,
      "loss": 0.0002,
      "step": 40536
    },
    {
      "epoch": 73.0,
      "grad_norm": 0.00010625278082443401,
      "learning_rate": 0.0001350088809946714,
      "loss": 0.0002,
      "step": 41099
    },
    {
      "epoch": 74.0,
      "grad_norm": 0.0009089743252843618,
      "learning_rate": 0.0001300088809946714,
      "loss": 0.0002,
      "step": 41662
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.007136906962841749,
      "learning_rate": 0.0001250088809946714,
      "loss": 0.0002,
      "step": 42225
    },
    {
      "epoch": 76.0,
      "grad_norm": 0.0002359958307351917,
      "learning_rate": 0.0001200088809946714,
      "loss": 0.0002,
      "step": 42788
    },
    {
      "epoch": 77.0,
      "grad_norm": 0.00035840156488120556,
      "learning_rate": 0.00011500888099467141,
      "loss": 0.0002,
      "step": 43351
    },
    {
      "epoch": 78.0,
      "grad_norm": 0.000900984916370362,
      "learning_rate": 0.0001100088809946714,
      "loss": 0.0002,
      "step": 43914
    },
    {
      "epoch": 79.0,
      "grad_norm": 0.0001308100181631744,
      "learning_rate": 0.0001050088809946714,
      "loss": 0.0001,
      "step": 44477
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.0035379137843847275,
      "learning_rate": 0.00010000888099467142,
      "loss": 0.0002,
      "step": 45040
    },
    {
      "epoch": 81.0,
      "grad_norm": 0.00034393902751617134,
      "learning_rate": 9.50088809946714e-05,
      "loss": 0.0001,
      "step": 45603
    },
    {
      "epoch": 82.0,
      "grad_norm": 0.0001287437480641529,
      "learning_rate": 9.00088809946714e-05,
      "loss": 0.0001,
      "step": 46166
    },
    {
      "epoch": 83.0,
      "grad_norm": 0.0007104348624125123,
      "learning_rate": 8.500888099467142e-05,
      "loss": 0.0001,
      "step": 46729
    },
    {
      "epoch": 84.0,
      "grad_norm": 1.5461160728591494e-05,
      "learning_rate": 8.00088809946714e-05,
      "loss": 0.0001,
      "step": 47292
    },
    {
      "epoch": 85.0,
      "grad_norm": 9.546327783027664e-05,
      "learning_rate": 7.50088809946714e-05,
      "loss": 0.0001,
      "step": 47855
    },
    {
      "epoch": 86.0,
      "grad_norm": 0.19224171340465546,
      "learning_rate": 7.000888099467139e-05,
      "loss": 0.0001,
      "step": 48418
    },
    {
      "epoch": 87.0,
      "grad_norm": 0.04403664171695709,
      "learning_rate": 6.50088809946714e-05,
      "loss": 0.0001,
      "step": 48981
    },
    {
      "epoch": 88.0,
      "grad_norm": 0.01569480448961258,
      "learning_rate": 6.0008880994671406e-05,
      "loss": 0.0001,
      "step": 49544
    },
    {
      "epoch": 89.0,
      "grad_norm": 9.121270704781637e-05,
      "learning_rate": 5.5008880994671406e-05,
      "loss": 0.0001,
      "step": 50107
    },
    {
      "epoch": 90.0,
      "grad_norm": 0.00020080590911675245,
      "learning_rate": 5.000888099467141e-05,
      "loss": 0.0,
      "step": 50670
    },
    {
      "epoch": 91.0,
      "grad_norm": 8.94048425834626e-05,
      "learning_rate": 4.50088809946714e-05,
      "loss": 0.0,
      "step": 51233
    },
    {
      "epoch": 92.0,
      "grad_norm": 2.5692426788737066e-05,
      "learning_rate": 4.000888099467141e-05,
      "loss": 0.0001,
      "step": 51796
    },
    {
      "epoch": 93.0,
      "grad_norm": 9.283457620767877e-05,
      "learning_rate": 3.50088809946714e-05,
      "loss": 0.0001,
      "step": 52359
    },
    {
      "epoch": 94.0,
      "grad_norm": 3.976418611273402e-06,
      "learning_rate": 3.0008880994671402e-05,
      "loss": 0.0001,
      "step": 52922
    },
    {
      "epoch": 95.0,
      "grad_norm": 0.00021555103012360632,
      "learning_rate": 2.5008880994671402e-05,
      "loss": 0.0,
      "step": 53485
    },
    {
      "epoch": 96.0,
      "grad_norm": 1.8794828065438196e-05,
      "learning_rate": 2.0008880994671406e-05,
      "loss": 0.0,
      "step": 54048
    },
    {
      "epoch": 97.0,
      "grad_norm": 0.0001034005981637165,
      "learning_rate": 1.5008880994671403e-05,
      "loss": 0.0,
      "step": 54611
    },
    {
      "epoch": 98.0,
      "grad_norm": 2.3263571620191215e-06,
      "learning_rate": 1.0008880994671404e-05,
      "loss": 0.0,
      "step": 55174
    },
    {
      "epoch": 99.0,
      "grad_norm": 5.323720324668102e-05,
      "learning_rate": 5.008880994671403e-06,
      "loss": 0.0,
      "step": 55737
    }
  ],
  "logging_steps": 0,
  "max_steps": 56300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 2330,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.37015525376e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
