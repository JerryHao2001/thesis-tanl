{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 100.0,
  "eval_steps": 500,
  "global_step": 46600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 0.3903723359107971,
      "learning_rate": 0.0004950107296137338,
      "loss": 0.1123,
      "step": 466
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.11838865280151367,
      "learning_rate": 0.0004900107296137339,
      "loss": 0.0244,
      "step": 932
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.274393767118454,
      "learning_rate": 0.0004850107296137339,
      "loss": 0.0179,
      "step": 1398
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.19307971000671387,
      "learning_rate": 0.0004800107296137339,
      "loss": 0.0139,
      "step": 1864
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.011832027696073055,
      "learning_rate": 0.00047501072961373395,
      "loss": 0.0113,
      "step": 2330
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.09743217378854752,
      "learning_rate": 0.00047001072961373394,
      "loss": 0.0091,
      "step": 2796
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.25586754083633423,
      "learning_rate": 0.0004650107296137339,
      "loss": 0.0075,
      "step": 3262
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.016908446326851845,
      "learning_rate": 0.0004600107296137339,
      "loss": 0.0066,
      "step": 3728
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.4541773498058319,
      "learning_rate": 0.0004550107296137339,
      "loss": 0.0059,
      "step": 4194
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.009435619227588177,
      "learning_rate": 0.0004500107296137339,
      "loss": 0.0055,
      "step": 4660
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.14580869674682617,
      "learning_rate": 0.0004450107296137339,
      "loss": 0.005,
      "step": 5126
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.05019716918468475,
      "learning_rate": 0.0004400107296137339,
      "loss": 0.0049,
      "step": 5592
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.02019212208688259,
      "learning_rate": 0.0004350107296137339,
      "loss": 0.0039,
      "step": 6058
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.17858116328716278,
      "learning_rate": 0.00043001072961373394,
      "loss": 0.0033,
      "step": 6524
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.01663787104189396,
      "learning_rate": 0.00042501072961373393,
      "loss": 0.0031,
      "step": 6990
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.016152717173099518,
      "learning_rate": 0.0004200107296137339,
      "loss": 0.0035,
      "step": 7456
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.0024491590447723866,
      "learning_rate": 0.0004150107296137339,
      "loss": 0.003,
      "step": 7922
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.07055293768644333,
      "learning_rate": 0.00041001072961373394,
      "loss": 0.0027,
      "step": 8388
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.004761440213769674,
      "learning_rate": 0.00040501072961373393,
      "loss": 0.0027,
      "step": 8854
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.002341039013117552,
      "learning_rate": 0.0004000107296137339,
      "loss": 0.0026,
      "step": 9320
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.0012217771727591753,
      "learning_rate": 0.0003950107296137339,
      "loss": 0.0025,
      "step": 9786
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.004951528273522854,
      "learning_rate": 0.0003900107296137339,
      "loss": 0.0023,
      "step": 10252
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.17726850509643555,
      "learning_rate": 0.0003850107296137339,
      "loss": 0.0024,
      "step": 10718
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.02795545943081379,
      "learning_rate": 0.0003800107296137339,
      "loss": 0.0019,
      "step": 11184
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.2632948160171509,
      "learning_rate": 0.0003750107296137339,
      "loss": 0.0019,
      "step": 11650
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.01977786421775818,
      "learning_rate": 0.0003700107296137339,
      "loss": 0.002,
      "step": 12116
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.0006288988515734673,
      "learning_rate": 0.00036501072961373394,
      "loss": 0.0019,
      "step": 12582
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.027647171169519424,
      "learning_rate": 0.0003600107296137339,
      "loss": 0.0017,
      "step": 13048
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.11561965942382812,
      "learning_rate": 0.0003550107296137339,
      "loss": 0.0016,
      "step": 13514
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.004508913028985262,
      "learning_rate": 0.00035001072961373395,
      "loss": 0.0017,
      "step": 13980
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.4973471226985566e-05,
      "learning_rate": 0.00034501072961373394,
      "loss": 0.0012,
      "step": 14446
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.034028470516204834,
      "learning_rate": 0.0003400107296137339,
      "loss": 0.0013,
      "step": 14912
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.05411645397543907,
      "learning_rate": 0.0003350107296137339,
      "loss": 0.0012,
      "step": 15378
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.0006495391135104001,
      "learning_rate": 0.0003300107296137339,
      "loss": 0.0015,
      "step": 15844
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.00572955422103405,
      "learning_rate": 0.0003250107296137339,
      "loss": 0.0011,
      "step": 16310
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.0036559721920639277,
      "learning_rate": 0.00032001072961373387,
      "loss": 0.0013,
      "step": 16776
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.16376033425331116,
      "learning_rate": 0.0003150107296137339,
      "loss": 0.0011,
      "step": 17242
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.00027628522366285324,
      "learning_rate": 0.0003100107296137339,
      "loss": 0.0011,
      "step": 17708
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.0033507586922496557,
      "learning_rate": 0.00030501072961373394,
      "loss": 0.001,
      "step": 18174
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.3514296117355116e-05,
      "learning_rate": 0.00030001072961373393,
      "loss": 0.0009,
      "step": 18640
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.15382634103298187,
      "learning_rate": 0.0002950107296137339,
      "loss": 0.0008,
      "step": 19106
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.03857472911477089,
      "learning_rate": 0.0002900107296137339,
      "loss": 0.0009,
      "step": 19572
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.0027634315192699432,
      "learning_rate": 0.00028501072961373394,
      "loss": 0.0011,
      "step": 20038
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.02037009969353676,
      "learning_rate": 0.00028001072961373393,
      "loss": 0.001,
      "step": 20504
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.01995265483856201,
      "learning_rate": 0.0002750107296137339,
      "loss": 0.0007,
      "step": 20970
    },
    {
      "epoch": 46.0,
      "grad_norm": 7.60217008064501e-05,
      "learning_rate": 0.0002700107296137339,
      "loss": 0.0008,
      "step": 21436
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.0003871326334774494,
      "learning_rate": 0.0002650107296137339,
      "loss": 0.0005,
      "step": 21902
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.02962017059326172,
      "learning_rate": 0.0002600107296137339,
      "loss": 0.0006,
      "step": 22368
    },
    {
      "epoch": 49.0,
      "grad_norm": 3.0493603844661266e-05,
      "learning_rate": 0.0002550107296137339,
      "loss": 0.0007,
      "step": 22834
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.0003620997304096818,
      "learning_rate": 0.0002500107296137339,
      "loss": 0.0005,
      "step": 23300
    },
    {
      "epoch": 51.0,
      "grad_norm": 0.00033547027851454914,
      "learning_rate": 0.0002450107296137339,
      "loss": 0.0006,
      "step": 23766
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.004807625897228718,
      "learning_rate": 0.0002400107296137339,
      "loss": 0.0006,
      "step": 24232
    },
    {
      "epoch": 53.0,
      "grad_norm": 0.002270117402076721,
      "learning_rate": 0.0002350107296137339,
      "loss": 0.0006,
      "step": 24698
    },
    {
      "epoch": 54.0,
      "grad_norm": 0.02926219068467617,
      "learning_rate": 0.0002300107296137339,
      "loss": 0.0006,
      "step": 25164
    },
    {
      "epoch": 55.0,
      "grad_norm": 4.317695857025683e-05,
      "learning_rate": 0.00022501072961373392,
      "loss": 0.0005,
      "step": 25630
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.0001226958993356675,
      "learning_rate": 0.0002200107296137339,
      "loss": 0.0005,
      "step": 26096
    },
    {
      "epoch": 57.0,
      "grad_norm": 0.001080077257938683,
      "learning_rate": 0.00021501072961373392,
      "loss": 0.0004,
      "step": 26562
    },
    {
      "epoch": 58.0,
      "grad_norm": 0.049879539757966995,
      "learning_rate": 0.0002100107296137339,
      "loss": 0.0004,
      "step": 27028
    },
    {
      "epoch": 59.0,
      "grad_norm": 0.15373307466506958,
      "learning_rate": 0.0002050107296137339,
      "loss": 0.0005,
      "step": 27494
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.0019179241498932242,
      "learning_rate": 0.0002000107296137339,
      "loss": 0.0004,
      "step": 27960
    },
    {
      "epoch": 61.0,
      "grad_norm": 0.00019357384007889777,
      "learning_rate": 0.00019501072961373392,
      "loss": 0.0004,
      "step": 28426
    },
    {
      "epoch": 62.0,
      "grad_norm": 0.27460798621177673,
      "learning_rate": 0.0001900107296137339,
      "loss": 0.0004,
      "step": 28892
    },
    {
      "epoch": 63.0,
      "grad_norm": 0.0007319339783862233,
      "learning_rate": 0.00018501072961373392,
      "loss": 0.0004,
      "step": 29358
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.00014678553270641714,
      "learning_rate": 0.0001800107296137339,
      "loss": 0.0004,
      "step": 29824
    },
    {
      "epoch": 65.0,
      "grad_norm": 6.644926907029003e-05,
      "learning_rate": 0.0001750107296137339,
      "loss": 0.0002,
      "step": 30290
    },
    {
      "epoch": 66.0,
      "grad_norm": 0.00021971140813548118,
      "learning_rate": 0.0001700107296137339,
      "loss": 0.0002,
      "step": 30756
    },
    {
      "epoch": 67.0,
      "grad_norm": 0.002410134533420205,
      "learning_rate": 0.0001650107296137339,
      "loss": 0.0002,
      "step": 31222
    },
    {
      "epoch": 68.0,
      "grad_norm": 8.798768976703286e-05,
      "learning_rate": 0.0001600107296137339,
      "loss": 0.0002,
      "step": 31688
    },
    {
      "epoch": 69.0,
      "grad_norm": 0.00015657366020604968,
      "learning_rate": 0.00015501072961373393,
      "loss": 0.0003,
      "step": 32154
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.0004489272250793874,
      "learning_rate": 0.0001500107296137339,
      "loss": 0.0003,
      "step": 32620
    },
    {
      "epoch": 71.0,
      "grad_norm": 0.0006636710604652762,
      "learning_rate": 0.0001450107296137339,
      "loss": 0.0002,
      "step": 33086
    },
    {
      "epoch": 72.0,
      "grad_norm": 6.781630418117857e-06,
      "learning_rate": 0.0001400107296137339,
      "loss": 0.0002,
      "step": 33552
    },
    {
      "epoch": 73.0,
      "grad_norm": 6.0019858210580423e-05,
      "learning_rate": 0.0001350107296137339,
      "loss": 0.0002,
      "step": 34018
    },
    {
      "epoch": 74.0,
      "grad_norm": 0.0003335175570100546,
      "learning_rate": 0.00013001072961373392,
      "loss": 0.0002,
      "step": 34484
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.0002608130744192749,
      "learning_rate": 0.0001250107296137339,
      "loss": 0.0002,
      "step": 34950
    },
    {
      "epoch": 76.0,
      "grad_norm": 1.4724943866895046e-05,
      "learning_rate": 0.00012001072961373392,
      "loss": 0.0002,
      "step": 35416
    },
    {
      "epoch": 77.0,
      "grad_norm": 0.00018327112775295973,
      "learning_rate": 0.0001150107296137339,
      "loss": 0.0001,
      "step": 35882
    },
    {
      "epoch": 78.0,
      "grad_norm": 1.5904821339063346e-05,
      "learning_rate": 0.00011001072961373392,
      "loss": 0.0001,
      "step": 36348
    },
    {
      "epoch": 79.0,
      "grad_norm": 0.0010571694001555443,
      "learning_rate": 0.0001050107296137339,
      "loss": 0.0001,
      "step": 36814
    },
    {
      "epoch": 80.0,
      "grad_norm": 8.052127668634057e-05,
      "learning_rate": 0.0001000107296137339,
      "loss": 0.0001,
      "step": 37280
    },
    {
      "epoch": 81.0,
      "grad_norm": 1.4242554243537597e-05,
      "learning_rate": 9.50107296137339e-05,
      "loss": 0.0001,
      "step": 37746
    },
    {
      "epoch": 82.0,
      "grad_norm": 5.901614349568263e-05,
      "learning_rate": 9.00107296137339e-05,
      "loss": 0.0001,
      "step": 38212
    },
    {
      "epoch": 83.0,
      "grad_norm": 9.068053623195738e-05,
      "learning_rate": 8.50107296137339e-05,
      "loss": 0.0001,
      "step": 38678
    },
    {
      "epoch": 84.0,
      "grad_norm": 0.00012925024202559143,
      "learning_rate": 8.00107296137339e-05,
      "loss": 0.0001,
      "step": 39144
    },
    {
      "epoch": 85.0,
      "grad_norm": 0.002522741910070181,
      "learning_rate": 7.50107296137339e-05,
      "loss": 0.0001,
      "step": 39610
    },
    {
      "epoch": 86.0,
      "grad_norm": 0.00013392165419645607,
      "learning_rate": 7.00107296137339e-05,
      "loss": 0.0001,
      "step": 40076
    },
    {
      "epoch": 87.0,
      "grad_norm": 2.025122921622824e-05,
      "learning_rate": 6.501072961373391e-05,
      "loss": 0.0001,
      "step": 40542
    },
    {
      "epoch": 88.0,
      "grad_norm": 0.00016883868374861777,
      "learning_rate": 6.00107296137339e-05,
      "loss": 0.0,
      "step": 41008
    },
    {
      "epoch": 89.0,
      "grad_norm": 3.3751901355572045e-05,
      "learning_rate": 5.501072961373391e-05,
      "loss": 0.0001,
      "step": 41474
    },
    {
      "epoch": 90.0,
      "grad_norm": 3.235398617107421e-05,
      "learning_rate": 5.001072961373391e-05,
      "loss": 0.0,
      "step": 41940
    },
    {
      "epoch": 91.0,
      "grad_norm": 0.0037410366348922253,
      "learning_rate": 4.50107296137339e-05,
      "loss": 0.0,
      "step": 42406
    },
    {
      "epoch": 92.0,
      "grad_norm": 3.536462099873461e-05,
      "learning_rate": 4.001072961373391e-05,
      "loss": 0.0,
      "step": 42872
    },
    {
      "epoch": 93.0,
      "grad_norm": 6.106529326643795e-05,
      "learning_rate": 3.501072961373391e-05,
      "loss": 0.0,
      "step": 43338
    },
    {
      "epoch": 94.0,
      "grad_norm": 0.00013080249482300133,
      "learning_rate": 3.0010729613733903e-05,
      "loss": 0.0,
      "step": 43804
    },
    {
      "epoch": 95.0,
      "grad_norm": 2.8878750526928343e-05,
      "learning_rate": 2.5010729613733907e-05,
      "loss": 0.0001,
      "step": 44270
    },
    {
      "epoch": 96.0,
      "grad_norm": 0.00016488856635987759,
      "learning_rate": 2.0010729613733904e-05,
      "loss": 0.0,
      "step": 44736
    },
    {
      "epoch": 97.0,
      "grad_norm": 5.094136213301681e-05,
      "learning_rate": 1.5010729613733906e-05,
      "loss": 0.0,
      "step": 45202
    },
    {
      "epoch": 98.0,
      "grad_norm": 4.716862895293161e-05,
      "learning_rate": 1.0010729613733905e-05,
      "loss": 0.0,
      "step": 45668
    },
    {
      "epoch": 99.0,
      "grad_norm": 0.0007728005875833333,
      "learning_rate": 5.010729613733906e-06,
      "loss": 0.0,
      "step": 46134
    }
  ],
  "logging_steps": 0,
  "max_steps": 46600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 2330,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.13327063433216e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
